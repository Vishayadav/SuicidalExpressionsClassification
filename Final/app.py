"""
Streamlit Frontend for Suicide Expression Classification
Supports direct text input and Instagram comment analysis with SHAP explainability
"""

import streamlit as st
import pandas as pd
import torch
from pathlib import Path
import os
import time
from datetime import datetime
import matplotlib.pyplot as plt
import io
import base64

# Import project utilities
from src.predict import get_model_and_tokenizer, predict_texts
from src.shap_utils import get_predict_proba, get_shap_explainer
from src.data_collection.instagram_comments import fetch_comments
import shap


# ============================================================================
# PAGE CONFIGURATION
# ============================================================================
st.set_page_config(
    page_title="Suicide Expression Classifier",
    page_icon="üîç",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# Custom CSS
st.markdown("""
<style>
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 20px;
        border-radius: 10px;
        margin: 10px 0;
    }
    .warning-card {
        background: #fff3cd;
        border: 1px solid #ffc107;
        padding: 15px;
        border-radius: 5px;
        margin: 10px 0;
    }
    .success-card {
        background: #d4edda;
        border: 1px solid #28a745;
        padding: 15px;
        border-radius: 5px;
        margin: 10px 0;
    }
</style>
""", unsafe_allow_html=True)


# ============================================================================
# CACHING & MODEL LOADING
# ============================================================================
@st.cache_resource
def load_model_and_tokenizer():
    """Load model and tokenizer once and cache for all sessions"""
    model_dir = Path(__file__).resolve().parent / 'model_test'
    tokenizer, model = get_model_and_tokenizer(model_dir=model_dir)
    return tokenizer, model


@st.cache_resource
def get_shap_explainer_cached(_tokenizer, _model):
    """Cache SHAP explainer"""
    device = torch.device('cpu')
    predict_proba = get_predict_proba(_model, _tokenizer, device=device)
    explainer = get_shap_explainer(predict_proba, _tokenizer)
    return explainer


# ============================================================================
# PREDICTION & SHAP FUNCTIONS
# ============================================================================
def predict_multiple_texts(texts, tokenizer, model, device='cpu'):
    """Predict labels for multiple texts"""
    results = predict_texts(texts, tokenizer, model, device=device)
    
    output = []
    for r in results:
        label = 'Suicidal' if r['pred'] == 1 else 'Non-Suicidal'
        confidence = r['prob']
        output.append({
            'text': r['text'],
            'prediction': label,
            'confidence': confidence,
            'probs': r['probs']
        })
    return output


def generate_shap_explanation(text, tokenizer, model, explainer):
    """Generate SHAP explanation for a single text"""
    try:
        device = torch.device('cpu')
        
        # Validate input
        if not isinstance(text, str):
            text = str(text)
        
        text = text.strip()
        if not text:
            st.warning("‚ö†Ô∏è Text is empty, cannot generate explanation")
            return None
        
        # Ensure text is not too long
        max_text_len = 512
        if len(text) > max_text_len:
            st.warning(f"‚ö†Ô∏è Text truncated to {max_text_len} characters for SHAP")
            text = text[:max_text_len]
        
        # Generate SHAP values
        shap_values = explainer([text])
        sv = shap_values[0]
        
        # Tokens
        tokens = sv.data
        
        # Create force plot for suicidal class (index 1)
        # Use matplotlib backend for better Streamlit compatibility
        shap_plot = shap.plots.force(
            sv.base_values[1],
            sv.values[:, 1],
            features=tokens,
            matplotlib=True,
            show=False
        )
        
        # Convert matplotlib figure to base64 image
        if shap_plot is not None:
            buf = io.BytesIO()
            shap_plot.savefig(buf, format='png', dpi=100, bbox_inches='tight')
            buf.seek(0)
            img_base64 = base64.b64encode(buf.read()).decode()
            html_str = f'<img src="data:image/png;base64,{img_base64}" style="max-width:100%; height:auto;">'
            plt.close(shap_plot)
            return html_str
        else:
            st.warning("‚ö†Ô∏è Could not generate SHAP visualization")
            return None
                
    except Exception as e:
        error_msg = f"Error generating SHAP: {str(e)[:120]}"
        st.error(f"‚ùå {error_msg}")
        return None


# ============================================================================
# SIDEBAR
# ============================================================================
# REMOVED - All content on main page now


# ============================================================================
# MAIN CONTENT
# ============================================================================
st.title("üîç Suicide Expression Classification")
st.markdown("Analyze text for suicidal expressions with AI-powered classification and SHAP explainability")

# Load model
with st.spinner("Loading model and tokenizer..."):
    tokenizer, model = load_model_and_tokenizer()
    explainer = get_shap_explainer_cached(tokenizer, model)

st.success("‚úÖ Model loaded successfully!")

st.markdown("---")

# Input Mode Selection
col1, col2 = st.columns(2)
with col1:
    input_mode = st.radio(
        "**Select Input Mode:**",
        ["üìù Direct Text Input", "üì∏ Instagram Link"],
        horizontal=True
    )

with col2:
    show_shap = st.checkbox("üî¨ Show SHAP Explanations", value=True)

st.markdown("---")


# ============================================================================
# DIRECT TEXT INPUT MODE
# ============================================================================
if input_mode == "üìù Direct Text Input":
    st.subheader("Enter Text for Classification")
    
    input_type = st.radio(
        "Choose input type:",
        ["Single Text", "Multiple Texts"],
        horizontal=True
    )
    
    if input_type == "Single Text":
        user_text = st.text_area(
            "Enter your text:",
            height=120,
            placeholder="Type or paste the text you want to analyze...",
            label_visibility="collapsed"
        )
        
        if st.button("üîç Classify", type="primary", use_container_width=True):
            if not user_text.strip():
                st.error("‚ùå Please enter some text to classify")
            else:
                with st.spinner("Analyzing text..."):
                    device = torch.device('cpu')
                    results = predict_multiple_texts([user_text], tokenizer, model, device=device)
                    result = results[0]
                    
                    st.markdown("---")
                    st.subheader("üìä Classification Results")
                    
                    # Display metrics
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Prediction", result['prediction'])
                    with col2:
                        st.metric("Confidence", f"{result['confidence']*100:.1f}%")
                    with col3:
                        risk_level = "üî¥ HIGH RISK" if result['prediction'] == 'Suicidal' else "üü¢ LOW RISK"
                        st.metric("Risk Level", risk_level)
                    
                    # Results table
                    df_single = pd.DataFrame([{
                        'Text': user_text,
                        'Prediction': result['prediction'],
                        'Confidence': f"{result['confidence']*100:.1f}%"
                    }])
                    st.dataframe(df_single, use_container_width=True)
                    
                    # SHAP Explanation
                    if show_shap:
                        st.markdown("---")
                        st.subheader("üî¨ SHAP Explanation - Word Importance")
                        st.markdown("The visualization shows how different words contribute to the classification:")
                        
                        with st.spinner("Generating SHAP explanation..."):
                            shap_html = generate_shap_explanation(user_text, tokenizer, model, explainer)
                            if shap_html:
                                st.components.v1.html(shap_html, height=300, scrolling=True)
    
    else:  # Multiple Texts
        texts_input = st.text_area(
            "Enter texts (one per line):",
            height=120,
            placeholder="Text 1\nText 2\nText 3\n...",
            label_visibility="collapsed"
        )
        
        if st.button("üîç Classify All", type="primary", use_container_width=True):
            texts_list = [t.strip() for t in texts_input.split('\n') if t.strip()]
            
            if not texts_list:
                st.error("‚ùå Please enter at least one text")
            else:
                with st.spinner(f"Analyzing {len(texts_list)} texts..."):
                    device = torch.device('cpu')
                    results = predict_multiple_texts(texts_list, tokenizer, model, device=device)
                    
                    st.markdown("---")
                    st.subheader("üìä Classification Results")
                    
                    # Summary statistics
                    suicidal_count = sum(1 for r in results if r['prediction'] == 'Suicidal')
                    non_suicidal_count = len(results) - suicidal_count
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Total Analyzed", len(results))
                    with col2:
                        st.metric("Suicidal", suicidal_count)
                    with col3:
                        st.metric("Non-Suicidal", non_suicidal_count)
                    
                    # Results table
                    df_results = pd.DataFrame({
                        'Text': [r['text'][:80] + ('...' if len(r['text']) > 80 else '') for r in results],
                        'Prediction': [r['prediction'] for r in results],
                        'Confidence': [f"{r['confidence']*100:.1f}%" for r in results]
                    })
                    
                    st.dataframe(df_results, use_container_width=True, height=400)
                    
                    # SHAP for each text
                    if show_shap:
                        st.markdown("---")
                        st.subheader("üî¨ SHAP Explanations")
                        
                        for idx, (text, result) in enumerate(zip(texts_list, results)):
                            with st.expander(f"**Text {idx+1}:** {result['prediction']} ({result['confidence']*100:.1f}%)"):
                                st.text(f"{text}")
                                
                                with st.spinner(f"Generating explanation for text {idx+1}..."):
                                    shap_html = generate_shap_explanation(text, tokenizer, model, explainer)
                                    if shap_html:
                                        st.components.v1.html(shap_html, height=250, scrolling=True)


# ============================================================================
# INSTAGRAM INPUT MODE
# ============================================================================
else:  # Instagram Link
    st.subheader("Analyze Instagram Post Comments")
    
    instagram_url = st.text_input(
        "Enter Instagram Post URL:",
        placeholder="https://www.instagram.com/p/ABC123XYZ/",
        help="Full URL to the Instagram post"
    )
    
    comment_limit = st.slider(
        "Number of Comments to Fetch:",
        min_value=1,
        max_value=200,
        value=10,
        step=5
    )
    
    if st.button("üîç Fetch and Analyze", type="primary", use_container_width=True):
        if not instagram_url.strip():
            st.error("‚ùå Please enter an Instagram URL")
        else:
            try:
                # Check for API token
                if not os.getenv("APIFY_API_TOKEN"):
                    st.error(
                        "‚ùå APIFY_API_TOKEN not set. Please set it in your `.env` file to use Instagram features."
                    )
                else:
                    with st.spinner(f"Fetching {comment_limit} comments from Instagram (this may take a moment)..."):
                        comments = fetch_comments(instagram_url, limit=comment_limit, debug=True)
                    
                    if not comments:
                        st.error("‚ùå No comments found. Check the URL or try again.")
                        
                        with st.expander("üîß Troubleshooting Help"):
                            st.markdown("""
                            **Possible reasons:**
                            - The Instagram post URL might be invalid
                            - The post might have no comments
                            - The post might be private or deleted
                            - Your APIFY_API_TOKEN might be invalid
                            
                            **Solutions:**
                            1. Verify the URL is a valid Instagram post URL
                            2. Make sure the post is public and has comments
                            3. Try a different post URL
                            4. Check your APIFY_API_TOKEN in the .env file
                            """)
                    else:
                        st.success(f"‚úÖ Fetched {len(comments)} comments from Instagram")
                        st.info(f"üìä Requested: {comment_limit} | Received: {len(comments)}")
                        
                        # Show parameters being used
                        with st.expander("üîç Debug Info - Scraping Strategy"):
                            st.markdown("""
**Multi-Attempt Strategy Used:**
1. First attempt: maxScrolls=10, resultsLimit up to 2x requested
2. Second attempt: maxScrolls=20, resultsLimit up to 3x requested  
3. Third attempt: maxScrolls=30, resultsLimit up to 5x requested

The scraper tries progressively more aggressive approaches until it gets the requested number of comments or exhausts all attempts.
                            """)
                            
                            with st.expander("üìä Statistics"):
                                st.info(f"""
**Fetch Summary:**
- Comments requested: {comment_limit}
- Comments fetched: {len(comments)}
- Success rate: {(len(comments)/comment_limit)*100:.1f}%

**Note:** If fewer comments are fetched than requested, it means:
- The post has fewer public comments available, OR
- Instagram/Apify rate limited the scraper, OR
- Some comments may be hidden/deleted

**Recommendation:** If you need more comments, try a different post.
                                """)
                        
                        with st.spinner("Classifying comments..."):
                            device = torch.device('cpu')
                            
                            # Prepare data
                            texts = [c.get("text", "") for c in comments]
                            usernames = [c.get("username", "Unknown") for c in comments]
                            
                            # Filter out empty texts
                            valid_indices = [i for i, t in enumerate(texts) if t.strip()]
                            texts = [texts[i] for i in valid_indices]
                            usernames = [usernames[i] for i in valid_indices]
                            
                            if not texts:
                                st.error("‚ùå No valid comments with text found.")
                            else:
                                st.info(f"üìä Fetched: {len(comments)} | Valid (with text): {len(texts)}")
                                
                                # Predict
                                predictions = predict_multiple_texts(texts, tokenizer, model, device=device)
                                
                                # Create results DataFrame with Username at the end
                                results_data = []
                                for username, comment_text, pred in zip(usernames, texts, predictions):
                                    results_data.append({
                                        'Username': username if username else 'Unknown',
                                        'Comment': comment_text[:150] + ('...' if len(comment_text) > 150 else ''),
                                        'Prediction': pred['prediction'],
                                        'Confidence': f"{pred['confidence']*100:.1f}%",
                                        '_full_text': comment_text,
                                        '_prediction_obj': pred
                                    })
                                
                                df_instagram = pd.DataFrame([{k: v for k, v in r.items() if not k.startswith('_')} for r in results_data])
                                
                                st.markdown("---")
                                st.subheader("üìä Classification Results")
                                
                                # Summary statistics
                                suicidal_count = sum(1 for r in results_data if r['Prediction'] == 'Suicidal')
                                non_suicidal_count = len(results_data) - suicidal_count
                                
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    st.metric("Total Analyzed", len(results_data))
                                with col2:
                                    st.metric("Suicidal", suicidal_count)
                                with col3:
                                    st.metric("Non-Suicidal", non_suicidal_count)
                                
                                # Display table
                                st.dataframe(df_instagram, use_container_width=True, height=400)
                                
                                # SHAP Explanations
                                if show_shap:
                                    st.markdown("---")
                                    st.subheader("üî¨ SHAP Explanations for Each Comment")
                                    st.markdown("Click to expand and see word-level importance for each comment")
                                    
                                    for idx, result_dict in enumerate(results_data):
                                        comment_text = result_dict['_full_text']
                                        pred = result_dict['_prediction_obj']
                                        username = result_dict['Username']
                                        
                                        with st.expander(
                                            f"**@{username}** - {pred['prediction']} ({pred['confidence']*100:.1f}%)"
                                        ):
                                            st.text(f"Comment: {comment_text}")
                                            
                                            try:
                                                # Validate text
                                                if not isinstance(comment_text, str) or not comment_text.strip():
                                                    st.warning("Cannot generate SHAP explanation for empty text")
                                                else:
                                                    with st.spinner("Generating SHAP explanation..."):
                                                        shap_html = generate_shap_explanation(
                                                            comment_text,
                                                            tokenizer,
                                                            model,
                                                            explainer
                                                        )
                                                        if shap_html:
                                                            st.components.v1.html(shap_html, height=250, scrolling=True)
                                            except Exception as e:
                                                st.error(f"‚ùå Error generating SHAP explanation: {str(e)[:100]}")
                                
                                # Download results
                                st.markdown("---")
                                csv = df_instagram.to_csv(index=False)
                                st.download_button(
                                    label="üì• Download Results as CSV",
                                    data=csv,
                                    file_name=f"instagram_classification_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                                    mime="text/csv"
                                )
            
            except Exception as e:
                st.error(f"‚ùå Error: {str(e)[:200]}")


# ============================================================================
# FOOTER
# ============================================================================
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center'>
        <small>
        Suicide Expression Classification System | Powered by DistilBERT + SHAP
        </small>
    </div>
    """,
    unsafe_allow_html=True
)
